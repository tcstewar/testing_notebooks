{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SSP encoding method (a.k.a. fractional power encoding, fractional binding, etc.) can be thought of as a single hidden layer of neurons whose activation functions are the `sin` function.  Here's how we can build that.\n",
    "\n",
    "We start with the normal encoding method we have been using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1043889  -0.08546952  0.15821391  0.19910652  0.21500024 -0.2994783\n",
      "  -0.08785525  0.25473042  0.08738421  0.18838902 -0.13542383 -0.1047516\n",
      "  -0.05760779 -0.01684594  0.15328399 -0.08690657  0.2282585   0.20040973\n",
      "   0.00719742 -0.2614392   0.04092408 -0.43821752  0.03885155 -0.03288524\n",
      "   0.03185555 -0.03305588  0.08908084  0.00407347  0.27975942  0.22905925\n",
      "  -0.15331175  0.28328137]]\n"
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "D = 32\n",
    "\n",
    "import sspspace\n",
    "encoder = sspspace.RandomSSPSpace(ssp_dim=D, domain_dim=2)\n",
    "\n",
    "x = np.array([3,1.2])\n",
    "x_ssp = encoder.encode(x)\n",
    "print(x_ssp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do that manually, rather than using the `encode` method, just to make sure we know what's going on.  \n",
    "\n",
    "The formula is $\\phi(x) = \\mathcal{F}^{-1}\\{e^{i\\theta x}\\}$ so let's go ahead and implement that, remembering that $e^{i\\theta} = cos(\\theta)+i sin(\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1043889  -0.08546952  0.15821391  0.19910652  0.21500024 -0.2994783\n",
      " -0.08785525  0.25473042  0.08738421  0.18838902 -0.13542383 -0.1047516\n",
      " -0.05760779 -0.01684594  0.15328399 -0.08690657  0.2282585   0.20040973\n",
      "  0.00719742 -0.2614392   0.04092408 -0.43821752  0.03885155 -0.03288524\n",
      "  0.03185555 -0.03305588  0.08908084  0.00407347  0.27975942  0.22905925\n",
      " -0.15331175  0.28328137]\n"
     ]
    }
   ],
   "source": [
    "phase = encoder.phase_matrix @ x\n",
    "x_ssp2 = np.fft.ifft(np.cos(phase)+1.0j*np.sin(phase)).real\n",
    "print(x_ssp2)\n",
    "assert np.allclose(x_ssp, x_ssp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fourier transform and its inverse are linear operations, so we can just generate the inverse Discrete Fourier Transform matrix and use that instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1043889  -0.08546952  0.15821391  0.19910652  0.21500024 -0.2994783\n",
      " -0.08785525  0.25473042  0.08738421  0.18838902 -0.13542383 -0.1047516\n",
      " -0.05760779 -0.01684594  0.15328399 -0.08690657  0.2282585   0.20040973\n",
      "  0.00719742 -0.2614392   0.04092408 -0.43821752  0.03885155 -0.03288524\n",
      "  0.03185555 -0.03305588  0.08908084  0.00407347  0.27975942  0.22905925\n",
      " -0.15331175  0.28328137]\n"
     ]
    }
   ],
   "source": [
    "phase = encoder.phase_matrix @ x\n",
    "idft = np.fft.ifft(np.eye(D))\n",
    "x_ssp3 = (idft @ (np.cos(phase)+1.0j*np.sin(phase))).real\n",
    "print(x_ssp3)\n",
    "assert np.allclose(x_ssp, x_ssp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse DFT matrix contains complex values, but we know the output is completely real.  So let's rewrite this to get rid of the use of complex numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1043889  -0.08546952  0.15821391  0.19910652  0.21500024 -0.2994783\n",
      " -0.08785525  0.25473042  0.08738421  0.18838902 -0.13542383 -0.1047516\n",
      " -0.05760779 -0.01684594  0.15328399 -0.08690657  0.2282585   0.20040973\n",
      "  0.00719742 -0.2614392   0.04092408 -0.43821752  0.03885155 -0.03288524\n",
      "  0.03185555 -0.03305588  0.08908084  0.00407347  0.27975942  0.22905925\n",
      " -0.15331175  0.28328137]\n"
     ]
    }
   ],
   "source": [
    "phase = encoder.phase_matrix @ x\n",
    "cos = np.cos(phase)\n",
    "sin = np.sin(phase)\n",
    "x_ssp4 = cos@idft.real - sin@idft.imag\n",
    "print(x_ssp4)\n",
    "assert np.allclose(x_ssp, x_ssp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the fact that the output is supposed to be real, there are symmetries in the phase matrix.  Because of this, we can actually just use the first half of the weight matrix.  This cuts the number of sines and cosines we have to compute in half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1043889  -0.08546952  0.15821391  0.19910652  0.21500024 -0.2994783\n",
      " -0.08785525  0.25473042  0.08738421  0.18838902 -0.13542383 -0.1047516\n",
      " -0.05760779 -0.01684594  0.15328399 -0.08690657  0.2282585   0.20040973\n",
      "  0.00719742 -0.2614392   0.04092408 -0.43821752  0.03885155 -0.03288524\n",
      "  0.03185555 -0.03305588  0.08908084  0.00407347  0.27975942  0.22905925\n",
      " -0.15331175  0.28328137]\n"
     ]
    }
   ],
   "source": [
    "phase = encoder.phase_matrix[:D//2] @ x\n",
    "cos = np.cos(phase)\n",
    "sin = np.sin(phase)\n",
    "\n",
    "assert D % 2 == 0   # we're assuming D is even in order to simplify the math here\n",
    "\n",
    "w = idft[D//2:].real.copy()\n",
    "w[1:] = w[::-1][:-1]\n",
    "w_cos = idft[:D//2].real + w\n",
    "\n",
    "w = idft[D//2:].imag.copy()\n",
    "w[1:] = -w[::-1][:-1]\n",
    "w_sin = idft[:D//2].imag + w\n",
    "\n",
    "x_ssp5 = cos @ w_cos - sin @ w_sin\n",
    "print(x_ssp5)\n",
    "assert np.allclose(x_ssp, x_ssp5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try implementing this network in Nengo, just to force it to be a completely normal neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1043889  -0.08546952  0.15821391  0.19910652  0.21500024 -0.2994783\n",
      " -0.08785525  0.25473042  0.08738421  0.18838902 -0.13542383 -0.1047516\n",
      " -0.05760779 -0.01684594  0.15328399 -0.08690657  0.2282585   0.20040973\n",
      "  0.00719742 -0.2614392   0.04092408 -0.43821752  0.03885155 -0.03288524\n",
      "  0.03185555 -0.03305588  0.08908084  0.00407347  0.27975942  0.22905925\n",
      " -0.15331175  0.28328137]\n"
     ]
    }
   ],
   "source": [
    "import nengo\n",
    "\n",
    "# define a sine-wave neuron model\n",
    "class SineNeuron(nengo.RectifiedLinear):\n",
    "    def step(self, dt, J, output):\n",
    "        output[...] = np.sin(J)\n",
    "\n",
    "model = nengo.Network()\n",
    "with model:\n",
    "    # an input with no non-linearity\n",
    "    stim = nengo.Node(x)\n",
    "    \n",
    "    # create a hidden layer with a sin() function for activation.  For the first D/2 of them,\n",
    "    #  we add a bias of pi/2 so that those ones are computing cos() instead of sin()\n",
    "    ssp_f = nengo.Ensemble(n_neurons=D, dimensions=1, \n",
    "                           neuron_type=SineNeuron(),\n",
    "                           gain=nengo.dists.Choice([1]), \n",
    "                           bias=np.concatenate([np.ones(D//2)*np.pi/2,np.zeros(D//2)]))\n",
    "    \n",
    "    # connect the inputs to the hidden layer, setting the connection weights to compute the phase matrix\n",
    "    nengo.Connection(stim, ssp_f.neurons, transform=np.concatenate([encoder.phase_matrix[:D//2], \n",
    "                                                                    encoder.phase_matrix[:D//2]]), synapse=None)\n",
    "    \n",
    "    # define the output layer (also without a nonlinearity)\n",
    "    ssp = nengo.Node(None, size_in=D)\n",
    "    # connect the output weights to compute the iDFT\n",
    "    nengo.Connection(ssp_f.neurons, ssp, transform=np.concatenate([w_cos, -w_sin]).T, synapse=None)\n",
    "    \n",
    "    p = nengo.Probe(ssp)\n",
    "    \n",
    "sim = nengo.Simulator(model, progress_bar=False)\n",
    "with sim:\n",
    "    sim.run(0.001)\n",
    "x_ssp6 = sim.data[p][-1]\n",
    "print(x_ssp6)\n",
    "assert np.allclose(x_ssp, x_ssp6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the sake of completeness, let's also implement this in Nengo OCL.  This requires writing an OpenCL implementation of the sine wave neuron type.  The code for that is just `outR = sin(J);` and the rest of the below code is just the hooks needed to tell `nengo_ocl` about the new neuron type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10438887 -0.08546952  0.15821394  0.19910657  0.21500024 -0.29947835\n",
      " -0.08785525  0.2547304   0.08738425  0.18838897 -0.13542378 -0.10475165\n",
      " -0.05760778 -0.01684602  0.153284   -0.08690657  0.22825852  0.20040962\n",
      "  0.00719745 -0.26143906  0.04092405 -0.43821752  0.03885158 -0.03288527\n",
      "  0.03185548 -0.0330558   0.08908083  0.00407355  0.2797594   0.22905919\n",
      " -0.1533118   0.28328145]\n"
     ]
    }
   ],
   "source": [
    "from nengo_ocl.utils import as_ascii\n",
    "from mako.template import Template   \n",
    "from nengo_ocl.clra_nonlinearities import _plan_template\n",
    "\n",
    "def plan_sine_neuron(queue, J, outR, **kwargs):\n",
    "    inputs = dict(J=J)\n",
    "    outputs = dict(outR=outR)\n",
    "    parameters = dict()\n",
    "    textconf = dict(type=J.ctype)\n",
    "\n",
    "    decs = \"\"\"\n",
    "        \"\"\"\n",
    "    text = \"\"\"\n",
    "        outR = sin(J);\n",
    "        \"\"\"\n",
    "    decs = as_ascii(Template(decs, output_encoding='ascii').render(**textconf))\n",
    "    text = as_ascii(Template(text, output_encoding='ascii').render(**textconf))\n",
    "    cl_name = \"cl_linear\"\n",
    "    return _plan_template(\n",
    "        queue, cl_name, text, declares=decs,\n",
    "        inputs=inputs, outputs=outputs, parameters=parameters, **kwargs) \n",
    "\n",
    "import nengo_ocl\n",
    "class SSPSimulator(nengo_ocl.Simulator):\n",
    "    def _plan_SineNeuron(self, ops):\n",
    "        J = self.all_data[[self.sidx[op.J] for op in ops]]\n",
    "        R = self.all_data[[self.sidx[op.output] for op in ops]]\n",
    "        return [plan_sine_neuron(self.queue, J, R)]\n",
    "    \n",
    "sim = SSPSimulator(model, progress_bar=False)\n",
    "with sim:\n",
    "    sim.run(0.001)\n",
    "    \n",
    "x_ssp7 = sim.data[p][-1]\n",
    "print(x_ssp7)\n",
    "assert np.allclose(x_ssp, x_ssp7, rtol=1e-4)  # nengo_ocl uses float32, not float64, so increase the tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
